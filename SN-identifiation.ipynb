{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "import pickle\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "from astropy.io import fits\n",
    "from scipy.ndimage import median_filter\n",
    "import math\n",
    "\n",
    "import glob\n",
    "from astropy.io import fits\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from keras import regularizers, callbacks\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import (Input, Dense, Activation, ZeroPadding1D, \n",
    "BatchNormalization, Flatten, Reshape, Conv1D, MaxPooling1D, Dropout,Add, LSTM,Embedding)\n",
    "from keras.initializers import glorot_normal, glorot_uniform\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model, load_model\n",
    "# from desispec.interpolation import resample_flux\n",
    "\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=plt.cm.tab10.colors)\n",
    "#plt.rcParamsDefault['axes.prop_cycle']\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['mathtext.fontset'] = 'dejavuserif'\n",
    "plt.rc('grid',alpha=0.3,linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "#retrieve file names of hosts\n",
    "files_host = np.sort(glob.glob('hosts/*.fits'))\n",
    "#create array of fluxes\n",
    "flux_host = []\n",
    "for f in files_host:\n",
    "    h = fits.open(f)\n",
    "    fl = h['BRZ_FLUX'].data\n",
    "    flux_host.append(fl)\n",
    "flux_host = np.concatenate(flux_host)\n",
    "\n",
    "\n",
    "#retrieve file names of SN    \n",
    "files_SN=np.sort(glob.glob('sneia/*.fits'))\n",
    "flux_SN = []\n",
    "for f in files_SN:\n",
    "    h = fits.open(f)\n",
    "    fl = h['BRZ_FLUX'].data\n",
    "    flux_SN.append(fl)\n",
    "flux_SN = np.concatenate(flux_SN)\n",
    "\n",
    "    \n",
    "# Get wavelength array (there is just one).\n",
    "h=fits.open(files_host[0])\n",
    "wave=h['BRZ_WAVELENGTH'].data\n",
    "\n",
    "#Get rid of 0 flux and NaN flux\n",
    "flux_host_reg=[]\n",
    "bad_host_counter=0\n",
    "for i in flux_host:\n",
    "    if np.sum(i)==0 or math.isnan(np.sum(i)):\n",
    "        bad_host_counter=bad_host_counter+1\n",
    "    else:\n",
    "        flux_host_reg.append(i)\n",
    "        \n",
    "flux_SN_reg=[]\n",
    "bad_SN_counter=0\n",
    "for i in flux_SN:\n",
    "    if np.sum(i)==0 or math.isnan(np.sum(i)):\n",
    "        bad_SN_counter=bad_SN_counter+1\n",
    "    else:\n",
    "        flux_SN_reg.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Median filter\n",
    "medianFilteredFlux149=[]\n",
    "for i in flux_host_reg:\n",
    "    trial_median_0 = median_filter(i,149)\n",
    "    medianFilteredFlux149.append(trial_median_0)\n",
    "    \n",
    "    \n",
    "medianFilteredFlux149_SN=[]\n",
    "for i in flux_SN_reg:\n",
    "    trial_median_0 = median_filter(i,149)\n",
    "    medianFilteredFlux149_SN.append(trial_median_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "medianFilteredFlux999=[]\n",
    "for i in flux_host_reg:\n",
    "    trial_median_1 = median_filter(i,999)\n",
    "    medianFilteredFlux999.append(trial_median_1)\n",
    "    \n",
    "medianFilteredFlux999_SN=[]\n",
    "for i in flux_SN_reg:\n",
    "    trial_median_1 = median_filter(i,999)\n",
    "    medianFilteredFlux999_SN.append(trial_median_1)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fit 3rd degree polynomial to approximate the galactic continuum\n",
    "polynomial_array=[]\n",
    "for i in flux_host_reg:\n",
    "    polynomial = np.polynomial.legendre.legfit(wave,i,3)\n",
    "    polynomial_array.append(polynomial)\n",
    "    \n",
    "polynomial_array_SN=[]\n",
    "for i in flux_SN_reg:\n",
    "    polynomial = np.polynomial.legendre.legfit(wave,i,3)\n",
    "    polynomial_array_SN.append(polynomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = []\n",
    "for i in range(len(medianFilteredFlux149)):\n",
    "    residual.append(medianFilteredFlux149[i] - np.polynomial.legendre.legval(wave, polynomial_array[i]))\n",
    "\n",
    "residual_SN = []\n",
    "for i in range(len(medianFilteredFlux149_SN)):\n",
    "    residual_SN.append(medianFilteredFlux149_SN[i] - np.polynomial.legendre.legval(wave, polynomial_array_SN[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "residual=np.asarray(residual)\n",
    "residual_SN=np.asarray(residual_SN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxflux = residual.max(axis=-1).reshape(-1,1)\n",
    "minflux = residual.min(axis=-1).reshape(-1,1)\n",
    "standarized_hosts = (residual - minflux)/(maxflux-minflux)\n",
    "\n",
    "maxflux_SN = residual_SN.max(axis=-1).reshape(-1,1)\n",
    "minflux_SN = residual_SN.min(axis=-1).reshape(-1,1)\n",
    "standarized = (residual_SN - minflux_SN)/(maxflux_SN-minflux_SN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(input_shape, learning_rate=0.0005, reg=0.0032, dropout=0.7436, seed=None):\n",
    "    \"\"\" \n",
    "    Args:\n",
    "    input_shape -- shape of the input spectra\n",
    "    regularization_strength -- regularization factor\n",
    "    dropout -- dropout rate\n",
    "    seed -- seed of initializer\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "\n",
    "    X_input = Input(input_shape, name='Input_Spec')\n",
    "\n",
    "    with K.name_scope('Conv_1'):\n",
    "        X = Conv1D(filters=8, kernel_size=5, strides=1, padding='same',\n",
    "                   kernel_regularizer=regularizers.l2(reg),\n",
    "                   bias_initializer='zeros',\n",
    "                   kernel_initializer=glorot_normal(seed))(X_input)\n",
    "        X = BatchNormalization(axis=2)(X)\n",
    "        X = Activation('relu')(X)\n",
    "        X = MaxPooling1D(pool_size= 2)(X)\n",
    "\n",
    "    with K.name_scope('Conv_2'):\n",
    "        X = Conv1D(filters=16, kernel_size=5, strides=1, padding='same',\n",
    "                   kernel_regularizer=regularizers.l2(reg),\n",
    "                   bias_initializer='zeros',\n",
    "                   kernel_initializer=glorot_normal(seed))(X)\n",
    "        X = BatchNormalization(axis=2)(X)\n",
    "        X = Activation('relu')(X)\n",
    "        X = MaxPooling1D(2)(X)\n",
    "    with K.name_scope('Conv_3'):\n",
    "        X = Conv1D(filters=32, kernel_size=5, strides=1, padding='same',\n",
    "                   kernel_regularizer=regularizers.l2(reg),\n",
    "                   bias_initializer='zeros',\n",
    "                   kernel_initializer=glorot_normal(seed))(X)\n",
    "        X = BatchNormalization(axis=2)(X)\n",
    "        X = Activation('relu')(X)\n",
    "        X = MaxPooling1D(2)(X)\n",
    "        \n",
    "    with K.name_scope('Conv_4'):\n",
    "        X = Conv1D(filters=64, kernel_size=5, strides=1, padding='same',\n",
    "                   kernel_regularizer=regularizers.l2(reg),\n",
    "                   bias_initializer='zeros',\n",
    "                   kernel_initializer=glorot_normal(seed))(X)\n",
    "        X = BatchNormalization(axis=2)(X)\n",
    "        X = Activation('relu')(X)\n",
    "        X = MaxPooling1D(2)(X)\n",
    "\n",
    "        \n",
    "    # FLATTEN -> FULLYCONNECTED\n",
    "    with K.name_scope('Dense_Layer'):\n",
    "        X = Flatten()(X)\n",
    "        X = Dense(256, kernel_regularizer=regularizers.l2(reg),\n",
    "                  activation='relu')(X)\n",
    "        X = Dropout(rate=dropout, seed=seed)(X)\n",
    "    \n",
    "    with K.name_scope('Output_Layer'):\n",
    "        X = Dense(1, kernel_regularizer=regularizers.l2(reg),\n",
    "              activation='sigmoid',name='Output_Classes')(X)\n",
    "\n",
    "    model = Model(inputs=X_input, outputs=X, name='SNnet')\n",
    "    model.compile(optimizer=Adam(lr=learning_rate), loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/amandawasserman/anaconda3/envs/desi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/amandawasserman/anaconda3/envs/desi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/amandawasserman/anaconda3/envs/desi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/amandawasserman/anaconda3/envs/desi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/amandawasserman/anaconda3/envs/desi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/amandawasserman/anaconda3/envs/desi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/amandawasserman/anaconda3/envs/desi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7436 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:From /Users/amandawasserman/anaconda3/envs/desi/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/amandawasserman/anaconda3/envs/desi/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model2 = network((6265,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate([standarized,standarized_hosts]).reshape(-1,6265,1)\n",
    "y_train = np.concatenate([np.zeros(standarized.shape[0]),np.ones(standarized_hosts.shape[0])])\n",
    "permute = np.random.permutation(y_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model2.fit(x_train[permute][:1996],y_train[permute][:1996],batch_size=64,epochs=50,\n",
    "                  validation_split=0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
